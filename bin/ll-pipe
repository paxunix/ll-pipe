#!/usr/bin/env zsh


function usage
{
    ${=TOOL_CAT} <<EOF
NAME
    $(progname) - process input in parallel

SYNOPSIS
    $(progname) [options] command [arg ...]

DESCRIPTION
    Reads line input from stdin in chunks and executes a command on each
    chunk.  Stdout and stderr from processing each chunk is output in the
    same order as the input.

    Conceptually:
        A B C D => command+arguments => A' B' C' D'
    where command+arguments are be applied to A, B, C and D in parallel.

ABOUT THE COMMAND
    The command is executed for each unique input chunk file (hereinafter
    referred to as INF) as follows:
        - INF is substituted for all occurrences of {} on the command's
          command line.  This allows the command to create extra output
          files with a known, per-chunk suffix for custom collection.
        - INF's contents are piped to command's stdin.
        - command's execution time, exit status, memory usage, etc. are
          written to INF.meta.
        - INF is removed only if command returns 0.  All INF* files are kept
          if the command fails (unless --clean-all is given).
        - the command's exit status is always written into the INF.done file
          once the command has exited.

ABOUT THE COLLECTORS
    All specified collectors are run in parallel.  The list of input chunk
    filenames is passed on stdin to each collector as each chunk finishes
    processing.  A collector can read the contents of each suffixed filename
    it is interested in and must remove the file once finished.

OPTIONS
    --clean-all
        Remove all files related to the input chunks, regardless of whether
        or not they were processed succesfully.

    --collector command+args
        Any number of --collector options can be given.  They are run in
        parallel as input chunks are been processed.  When each chunk
        finishes processing, its filename is passed on stdin to each
        collector.  If command+args contains shell-metacharacters or spaces,
        wrap it in single quotes.

        If no collectors are specified, the special +stdout and +stderr
        collectors are enabled.  The +stdout collector collects the .out
        file containing the stdout output from processing each chunk and
        dumps it to stdout, preserving order.  The +stderr collector does
        the same thing, but for stderr in the .err files, and dumps it to
        stderr, in order.

        If at least one collector is specified, the +stdout and +stderr
        collectors are NOT enabled.  If stdout and stderr collection is
        still desired, the collectors for them must be specified.

    --lines-per-chunk num
        Optional.  The input data will be split into files with a maximum of
        num lines in each file.  Default is 1000.

    --max-attempts num
        Optional.  Will retry the command num times on the same input chunk
        before giving up.  Default is 5.

    --max-jobs num
        Optional.  Will run the command on num chunks in parallel until all
        input is consumed.  Default is 1.

    --meta-outfile file
        Optional.  Meta information (e.g. runtime, exit status, etc.) will
        be collected for various parts of the pipeline and saved to file.

    --retry-delay
        Optional.  Number of seconds to sleep in between retry attempts.
        This is a number or a zsh arithmetic expression that can use the
        'numAttempts' variable, which contains the number of times the
        command has failed.  Default is 0.  For example, you could back-off
        on retries:
            --retry-delay '$((numAttempts * 60))'

    --retry-failure-fatal
        Optional.  If the final retry of a command fails, all current
        processing is terminated and no further input will be processed.
        The default behaviour is to continue processing even if one chunk
        fails processing.

    --verbose
        Optional.  Output diagnostic status info to file descriptor 3.  If
        fd 3 is not already redirected, it will be redirected to stderr.

OPERANDS
    command     The command to execute for each input chunk.  It receives
                the chunk's data on stdin.

    arg         Arguments passed to the given command.

EXIT STATUS
    0   Every chunk was successfully processed.
    !0  Processing/collection failed for at least one chunk.
EOF
}   # usage


# The collector manager runs in the background and is started before any
# input is actually processed.  It scans continually the next chunk of
# processed data, and once it's available, passes it to the collectors and
# continues until all chunks are finished.
function collectorManager
{
    local curChunk=1
    while true
    do
        if [[ -e ${tempDir}/${curChunk}.done ]]
        then
            print -r -- ${tempDir}/$(( curChunk++ ))

            # Only stop the loop if the next chunk does not exist and all
            # chunks are done.
            [[ -e ${tempDir}/chunks-done &&
               ! -e ${tempDir}/${curChunk}.done ]] && break
        else
            ${=TOOL_SLEEP} 1
        fi
    done
}   # collectorManager


# Runs a collector with timeCommand so we can get stats on collectors.
function runCollector
{
    local collectorMetafile=$(${=TOOL_MKTEMP} ${tempDir}/${$}.${0:t}.meta-collector.XXXXXXXXXX)

    verbose "Starting collector ${(z)@}"

    eval timeCommand \
        --kv "action:collector" \
        --output ${collectorMetafile} \
        ${(z)@}
}   # runCollector


# Main

setopt nofunctionargzero

. ${0:h}/../etc/ll-pipe-fns || return 1

enableDebug && setopt xtrace

local -a collectors
zparseopts -D -E -- \
    "-collector+:=collectors"

# Remove --collector option names
collectors=( ${collectors:#--collector} )

local -A opts
zparseopts -D -A opts -- \
    "-clean-all" \
    "-lines-per-chunk:" \
    "-max-attempts:" \
    "-max-jobs:" \
    "-meta-outfile:" \
    "-retry-delay:" \
    "-retry-failure-fatal" \
    "-verbose" \

if [[ ${1} == -* ]]     # Probably an unknown option
then
    error "Unknown option: ${1}"
    usage
    return 1
fi

if [[ -z ${1} ]]
then
    error "No command was given."
    return 1
fi

# Set default parameters if necessary.
: ${opts[--lines-per-chunk]:=1000}
: ${opts[--max-attempts]:=5}
: ${opts[--max-jobs]:=1}
: ${opts[--meta-outfile]:=/dev/null}
: ${opts[--retry-delay]:=0}

if (( ${+opts[--verbose]} ))
then
    export ll_pipe_verbose=1

    # Since verbose output is written to fd 3, make sure it's open.
    # If it's not, redirect it to stderr.
    eval ': >&3' 2>/dev/null || exec 3>&2

fi

local tempDir=$(${=TOOL_MKTEMP} -d $(absPath ${TMPDIR:-.})/${$}.${0:t}.XXXXXXXXXX)
if (( ${?} ))
then
    error "Failed to create temporary work directory."
    return 1
fi

# Predefined collectors
local -A predefCollector2Command
predefCollector2Command=(
    +stdout         "${=TOOL_LL_PIPE_COLLECT_BY_SUFFIX} \
                        --successful-only \
                        --suffix .out \
                        --output-file /dev/stdout"

    +stderr         "${=TOOL_LL_PIPE_COLLECT_BY_SUFFIX} \
                        --successful-only \
                        --suffix .err \
                        --output-file /dev/stderr"

    +meta           "${=TOOL_LL_PIPE_COLLECT_BY_SUFFIX} \
                        --successful-only \
                        --suffix .meta \
                        --output-file ${opts[--meta-outfile]}"
)

# If no collectors were specified, enable +stdout and +stderr.
if (( ${#collectors} == 0 ))
then
    collectors=( +stdout +stderr )
fi

# Always enable the meta collector.
collectors+=( +meta )

# Empty the meta collector output file.
: > ${opts[--meta-outfile]}

# Replace any predefined collector names with their commands.
local i
for ((i = 1; i <= ${#collectors}; i++))
do
    if (( ${+predefCollector2Command[${collectors[i]}]} ))
    then
        collectors[i]=${predefCollector2Command[${collectors[i]}]}
    fi
done

# Run the collector manager in the background.  The eval is used to run all
# collectors simultaneously with multios.
eval collectorManager ${collectors/(#b)(*)/> >(runCollector ${(q)match})} &

# Ensure the collector manager and its collectors are killed on likely
# signals.
trap 'kill %?collectorManager 2>/dev/null' \
    INT HUP TERM USR1 USR2 QUIT ABRT

# Split input into chunks and save the chunk names to a file so we can
# combine everything later.
verbose "Splitting input into chunks"

${=TOOL_LL_PIPE_SPLIT} \
    --lines-per-chunk ${opts[--lines-per-chunk]} \
    --directory ${tempDir} |

# Process each chunk.
${=TOOL_XARGS} \
    --max-lines=1 \
    --max-procs=${opts[--max-jobs]} \
    --no-run-if-empty \
    --replace='{}' \
    ${=TOOL_LL_PIPE_WORKER} \
        --max-attempts ${opts[--max-attempts]} \
        --retry-delay ${opts[--retry-delay]} \
        ${(k)opts[--retry-failure-fatal]} \
        --input-file '{}' \
        ${@}

local xargsError=${?}

# Signal the collector manager that all input chunks have been processed.
: > ${tempDir}/chunks-done

verbose "All chunks processed."

wait        # Wait for the collector manager to complete.

# Collect meta files from collectors.  Order doesn't matter.
print -r -l -- ${tempDir}/*.meta-collector.*(N) |
    ${=TOOL_LL_PIPE_COLLECT_BY_SUFFIX} \
        --suffix '' \
        --output-file ${opts[--meta-outfile]}

if (( ${+opts[--clean-all]} ))
then
    builtin cd -
    ${=TOOL_RM} -fr ${tempDir}
else
    # If not cleaning up everything, only remove chunk-related files for
    # successful chunks.
    local file
    print -l -r -- ${tempDir}/[0-9]##.done(N) |
    while read -r file
    do
        (( ${(f)"$(< ${file})":-1} == 0 )) && print -l -r -- ${file:r}{,.*}
    done |
    ${=TOOL_XARGS} \
        --max-procs=${opts[--max-jobs]} \
        --no-run-if-empty \
        ${=TOOL_RM} -f

    ${=TOOL_RM} -f ${tempDir}/chunks-done ${tempDir}/chunk-count

    # Try to remove our temporary dir.  Ignore failure since it may have
    # files from failed chunks in it.
    builtin cd -
    ${=TOOL_RMDIR} --ignore-fail-on-non-empty ${tempDir}
fi

if (( ${xargsError} ))
then
    verbose "Failed."
else
    verbose "Succeeded."
fi

return ${xargsError}

# vim: ft=zsh
